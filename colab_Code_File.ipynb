{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Mn_svmfoxr",
        "outputId": "a42aa063-291c-4c62-d16b-96f135424c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qdrant_client in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant_client) (1.76.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant_client) (2.0.2)\n",
            "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from qdrant_client) (3.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant_client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant_client) (2.12.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant_client) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.41.0->qdrant_client) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install qdrant_client\n",
        "\n",
        "from qdrant_client import QdrantClient, models\n",
        "from google.colab import userdata\n",
        "client = QdrantClient(\n",
        "    url=\"https://3b0be7da-3d6c-4e40-b46f-497540721020.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.PaoAOjwVAsbCeknlDU9UPUMvYMZXF6TfX7OhrkSkAHE\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"disaster_response_system\"\n",
        "\n",
        "# Check if the collection already exists before creating it\n",
        "if client.collection_exists(collection_name=collection_name):\n",
        "    print(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
        "else:\n",
        "    # Use named vectors to handle multimodal data spaces\n",
        "    client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config={\n",
        "            \"text_sos\": models.VectorParams(size=768, distance=models.Distance.COSINE),  # e.g. for Gemini\n",
        "            \"image_drone\": models.VectorParams(size=512, distance=models.Distance.COSINE), # e.g. for CLIP\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeLIHdZGgVoQ",
        "outputId": "30169068-d6fa-4e58-bcd9-1435516619e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'disaster_response_system' already exists. Skipping creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Geo-location index for proximity searches\n",
        "client.create_payload_index(\n",
        "    collection_name=collection_name,\n",
        "    field_name=\"location\",\n",
        "    field_schema=models.PayloadSchemaType.GEO\n",
        ")\n",
        "\n",
        "# 2. Status index (Keyword) to filter \"pending\" vs \"assisted\"\n",
        "client.create_payload_index(\n",
        "    collection_name=collection_name,\n",
        "    field_name=\"status\",\n",
        "    field_schema=models.PayloadSchemaType.KEYWORD\n",
        ")\n",
        "\n",
        "# 3. Severity score index (Integer) for prioritization\n",
        "client.create_payload_index(\n",
        "    collection_name=collection_name,\n",
        "    field_name=\"severity_score\",\n",
        "    field_schema=models.PayloadSchemaType.INTEGER\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfnGOGOugZpH",
        "outputId": "ee08a3dc-5e8a-48cb-fe6e-21c4a0e2ce35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UpdateResult(operation_id=89, status=<UpdateStatus.COMPLETED: 'completed'>)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ensure data follows your strict metadata schema\n",
        "def ingest_emergency_data(point_id, text_vec, img_vec, lat, lon, severity, status):\n",
        "    # Ensure img_vec is a list of floats, even if it's a zero vector if not provided\n",
        "    if img_vec is None:\n",
        "        # Assuming the image_drone vector size is 512 as defined in collection creation\n",
        "        img_vec_processed = [0.0] * 512\n",
        "    else:\n",
        "        img_vec_processed = img_vec\n",
        "\n",
        "    client.upsert(\n",
        "        collection_name=\"disaster_response_system\",\n",
        "        points=[\n",
        "            models.PointStruct(\n",
        "                id=point_id,\n",
        "                vector={\n",
        "                    \"text_sos\": text_vec,\n",
        "                    \"image_drone\": img_vec_processed # Use the processed image vector\n",
        "                },\n",
        "                payload={\n",
        "                    \"location\": {\"lat\": lat, \"lon\": lon}, # GEO\n",
        "                    \"severity_score\": severity,           # INT\n",
        "                    \"status\": status,                     # KEYWORD\n",
        "                    \"timestamp\": \"2026-01-18T10:43:00Z\",  # ISO String\n",
        "                    \"traceable_id\": f\"EVT-{point_id}\"     # For Evidence-based output\n",
        "                }\n",
        "            )\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "342Poue-hhO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from datetime import datetime\n",
        "\n",
        "def disaster_memory_pipeline(text_vec, img_vec, lat, lon, incoming_severity):\n",
        "    # 1. STATE MANAGEMENT: Check if an event already exists within a 500m geo-fence\n",
        "    # This satisfies the requirement to check for existing reports in a specific area.\n",
        "    search_result = client.search(\n",
        "    collection_name=\"emergency_data\",\n",
        "    query_vector=(\"text_sos\", query_vector),\n",
        "    limit=5\n",
        ")\n",
        "\n",
        "    query_filter={\n",
        "        \"must\": [\n",
        "            {\"key\": \"status\", \"match\": {\"value\": \"to_visit\"}}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # 2. OVERRIDE RULES & MEMORY EVOLUTION\n",
        "    if search_result:\n",
        "        # Existing report found! We update the memory instead of duplicating.\n",
        "        existing_point = search_result[0]\n",
        "        point_id = existing_point.id\n",
        "\n",
        "        # Logic: If new severity is higher, we override the old one [cite: 25, 26]\n",
        "        new_severity = max(existing_point.payload['severity_score'], incoming_severity)\n",
        "        current_status = existing_point.payload['status']\n",
        "        print(f\"Updating existing memory at {point_id}. New Severity: {new_severity}\")\n",
        "    else:\n",
        "        # No existing report in this geo-fence: Create a new unique memory\n",
        "        point_id = str(uuid.uuid4())\n",
        "        new_severity = incoming_severity\n",
        "        current_status = \"pending\"\n",
        "        print(f\"Creating new emergency record with ID: {point_id}\")\n",
        "\n",
        "    # 3. EXECUTE THE UPSERT\n",
        "    # This satisfies \"Memory beyond a single prompt\" [cite: 27, 120]\n",
        "    client.upsert(\n",
        "        collection_name=collection_name,\n",
        "        points=[\n",
        "            models.PointStruct(\n",
        "                id=point_id,\n",
        "                vector={\"text_sos\": text_vec, \"image_drone\": img_vec},\n",
        "                payload={\n",
        "                    \"location\": {\"lat\": lat, \"lon\": lon},\n",
        "                    \"severity_score\": new_severity,\n",
        "                    \"status\": current_status,\n",
        "                    \"last_updated\": datetime.now().isoformat(),\n",
        "                    \"report_count\": (existing_point.payload.get('report_count', 0) + 1) if search_result else 1\n",
        "                }\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return point_id"
      ],
      "metadata": {
        "id": "aXbawZhDgfeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_responder_status(point_id, new_status):\n",
        "    \"\"\"\n",
        "    Simulates an API endpoint for responders.\n",
        "    Valid statuses: 'pending', 'visiting', 'already assisted'\n",
        "    \"\"\"\n",
        "    client.set_payload(\n",
        "        collection_name=collection_name,\n",
        "        payload={\"status\": new_status},\n",
        "        points=[point_id],\n",
        "        wait=True\n",
        "    )\n",
        "    print(f\"Location {point_id} marked as {new_status}. Memory updated.\")"
      ],
      "metadata": {
        "id": "OBJuvRVSiNhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Participant-----B-----start-------here"
      ],
      "metadata": {
        "id": "BTwFnj_7pmRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSLPbUOPpyaY",
        "outputId": "dc4f6877-184a-467e-d97d-e5498ff56186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-mpnet-base-v2\") # Changed model to produce 768-dim vectors\n",
        "\n",
        "text = \"People trapped due to flood\"\n",
        "vector = model.encode(text)\n",
        "\n",
        "print(len(vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAK3vrzsp3WI",
        "outputId": "cd3dc783-ba7b-4b1e-ee95-c1049587305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def severity_score(text):\n",
        "    text = text.lower()\n",
        "    if \"trapped\" in text and \"flood\" in text:\n",
        "        return 9\n",
        "    if \"injured\" in text:\n",
        "        return 8\n",
        "    return 5\n",
        "\n",
        "severity = severity_score(text)\n",
        "print(severity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if5Uv48Dp7_M",
        "outputId": "12544429-317c-450b-9c37-cc6c253a8136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Generate a UUID for the point_id\n",
        "point_id = str(uuid.uuid4())\n",
        "\n",
        "# Calculate severity using the defined function\n",
        "severity = severity_score(text)\n",
        "\n",
        "ingest_emergency_data(\n",
        "    point_id=point_id,\n",
        "    text_vec=vector.tolist(),\n",
        "    img_vec=None,\n",
        "    lat=23.5,\n",
        "    lon=85.3,\n",
        "    severity=10,\n",
        "    status=\"to_visit\"\n",
        ")\n",
        "\n",
        "print(\"Data sent to backend successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuG1hdGJqNlp",
        "outputId": "f2572295-434a-4670-9e9b-522f62c2e706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data sent to backend successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-tGTqKkqdTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
